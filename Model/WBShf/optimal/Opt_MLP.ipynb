{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, cross_val_predict\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the .mat file\n",
    "data = sio.loadmat('../data/ML_Optimal_method.mat')\n",
    "eddy_double_LES = data['eddy_double_LES']\n",
    "eddy_double_TBNN = data['eddy_double_TBNN']\n",
    "Sij = data['Sij']\n",
    "Rij = data['Rij']\n",
    "x = data['x']\n",
    "y = data['y']\n",
    "x_point = data['x_point']\n",
    "y_point = data['y_point']\n",
    "bij_LES = data['bij_LES']\n",
    "bij_TBNN = data['bij_TBNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edd viscosity = function(Sij, Rij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variables\n",
    "# Use columns 0, 1, 3, and 4 from Sij an Rij as features\n",
    "X = np.concatenate((Sij[:, [0, 1, 3, 4]], Rij[:, [0, 1, 3, 4]]), axis=1)\n",
    "Y = eddy_double_TBNN.ravel()\n",
    "Y_LES = eddy_double_LES.ravel()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define parameter grid for MLPRegressor hyperparameters\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization term\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize an MLPRegressor\n",
    "mlp = MLPRegressor(solver='adam', random_state=42)\n",
    "\n",
    "# Perform GridSearchCV with 5-fold cross-validation to find best hyperparameters\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_scaled, Y)\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "print(\"Best hyperparameters from GridSearchCV:\", best_params)\n",
    "print(\"Best RMSE from GridSearchCV:\", best_rmse)\n",
    "\n",
    "# Initialize final MLPRegressor with the best hyperparameters\n",
    "final_mlp = MLPRegressor(solver='adam', random_state=42, **best_params)\n",
    "\n",
    "# Evaluate the model using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(final_mlp, X_scaled, Y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-np.mean(cv_scores))\n",
    "print(\"MLPRegressor Cross-validated RMSE:\", cv_rmse)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "Y_pred_cv = cross_val_predict(final_mlp, X_scaled, Y, cv=kf)\n",
    "print(\"MLPRegressor Cross-validated R2:\", r2_score(Y, Y_pred_cv))\n",
    "\n",
    "# Train the final MLPRegressor on the full dataset\n",
    "final_mlp.fit(X_scaled, Y)\n",
    "Y_pred = final_mlp.predict(X_scaled)\n",
    "print(\"MLPRegressor Training RMSE:\", np.sqrt(mean_squared_error(Y, Y_pred)))\n",
    "print(\"MLPRegressor Training R2:\", r2_score(Y, Y_pred))\n",
    "\n",
    "# Plot predictions vs. actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_LES, label='Actual eddy_double_LES', color='green')\n",
    "plt.plot(Y, label='Actual eddy_double_TBNN', color='blue')\n",
    "plt.plot(Y_pred, label='MLP Prediction (Train)', color='red', linestyle='--')\n",
    "plt.plot(Y_pred_cv, label='MLP Prediction (CV)', color='orange', linestyle='-.')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('MLPRegressor Prediction vs. Actual')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interpolate the results onto the spatial grid\n",
    "points = np.column_stack((x_point.ravel(), y_point.ravel()))\n",
    "eddy_double_LES_interp = griddata(points, eddy_double_LES.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "eddy_double_TBNN_interp = griddata(points, eddy_double_TBNN.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "Y_pred_interp = griddata(points, Y_pred.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "\n",
    "# Set common color scale limits for the spatial plots\n",
    "vmin = -0.05\n",
    "vmax = 0.20\n",
    "\n",
    "# Plot the interpolated maps in a vertical stack (3 subplots)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "im0 = axs[0].pcolormesh(x, y, eddy_double_LES_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title('eddy double LES')\n",
    "axs[0].set_aspect('equal', adjustable='box')\n",
    "axs[0].set_xlim(np.min(x), np.max(x))\n",
    "axs[0].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im1 = axs[1].pcolormesh(x, y, eddy_double_TBNN_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_title('eddy double TBNN')\n",
    "axs[1].set_aspect('equal', adjustable='box')\n",
    "axs[1].set_xlim(np.min(x), np.max(x))\n",
    "axs[1].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im2 = axs[2].pcolormesh(x, y, Y_pred_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_title('MLPRegressor Y pred')\n",
    "axs[2].set_aspect('equal', adjustable='box')\n",
    "axs[2].set_xlim(np.min(x), np.max(x))\n",
    "axs[2].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "fig.subplots_adjust(right=0.85, hspace=0.1)\n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im2, cax=cbar_ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edd viscosity = function(Sij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variables\n",
    "# Use columns 0, 1, 3, and 4 from Sij as features\n",
    "X = Sij[:, [0, 1, 3, 4]]\n",
    "# Use eddy_double_TBNN as the target variable, and eddy_double_LES as a reference\n",
    "Y = eddy_double_TBNN.ravel()\n",
    "Y_LES = eddy_double_LES.ravel()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define parameter grid for MLPRegressor hyperparameters\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization term\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize an MLPRegressor\n",
    "mlp = MLPRegressor(solver='adam', random_state=42)\n",
    "\n",
    "# Perform GridSearchCV with 5-fold cross-validation to find best hyperparameters\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_scaled, Y)\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "print(\"Best hyperparameters from GridSearchCV:\", best_params)\n",
    "print(\"Best RMSE from GridSearchCV:\", best_rmse)\n",
    "\n",
    "# Initialize final MLPRegressor with the best hyperparameters\n",
    "final_mlp = MLPRegressor(solver='adam', random_state=42, **best_params)\n",
    "\n",
    "# Evaluate the model using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(final_mlp, X_scaled, Y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-np.mean(cv_scores))\n",
    "print(\"MLPRegressor Cross-validated RMSE:\", cv_rmse)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "Y_pred_cv = cross_val_predict(final_mlp, X_scaled, Y, cv=kf)\n",
    "print(\"MLPRegressor Cross-validated R2:\", r2_score(Y, Y_pred_cv))\n",
    "\n",
    "# Train the final MLPRegressor on the full dataset\n",
    "final_mlp.fit(X_scaled, Y)\n",
    "Y_pred = final_mlp.predict(X_scaled)\n",
    "print(\"MLPRegressor Training RMSE:\", np.sqrt(mean_squared_error(Y, Y_pred)))\n",
    "print(\"MLPRegressor Training R2:\", r2_score(Y, Y_pred))\n",
    "\n",
    "# Plot predictions vs. actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_LES, label='Actual eddy_double_LES', color='green')\n",
    "plt.plot(Y, label='Actual eddy_double_TBNN', color='blue')\n",
    "plt.plot(Y_pred, label='MLP Prediction (Train)', color='red', linestyle='--')\n",
    "plt.plot(Y_pred_cv, label='MLP Prediction (CV)', color='orange', linestyle='-.')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('MLPRegressor Prediction vs. Actual')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interpolate the results onto the spatial grid\n",
    "points = np.column_stack((x_point.ravel(), y_point.ravel()))\n",
    "eddy_double_LES_interp = griddata(points, eddy_double_LES.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "eddy_double_TBNN_interp = griddata(points, eddy_double_TBNN.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "Y_pred_interp = griddata(points, Y_pred.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "\n",
    "# Set common color scale limits for the spatial plots\n",
    "vmin = -0.05\n",
    "vmax = 0.20\n",
    "\n",
    "# Plot the interpolated maps in a vertical stack (3 subplots)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "im0 = axs[0].pcolormesh(x, y, eddy_double_LES_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title('eddy double LES')\n",
    "axs[0].set_aspect('equal', adjustable='box')\n",
    "axs[0].set_xlim(np.min(x), np.max(x))\n",
    "axs[0].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im1 = axs[1].pcolormesh(x, y, eddy_double_TBNN_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_title('eddy double TBNN')\n",
    "axs[1].set_aspect('equal', adjustable='box')\n",
    "axs[1].set_xlim(np.min(x), np.max(x))\n",
    "axs[1].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im2 = axs[2].pcolormesh(x, y, Y_pred_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_title('MLPRegressor Y pred')\n",
    "axs[2].set_aspect('equal', adjustable='box')\n",
    "axs[2].set_xlim(np.min(x), np.max(x))\n",
    "axs[2].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "fig.subplots_adjust(right=0.85, hspace=0.1)\n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im2, cax=cbar_ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edd viscosity = function(Sij, bij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variables\n",
    "# Use columns 0, 1, 3, and 4 from Sij as features and bij_LES as additional features\n",
    "X = np.concatenate((Sij[:, [0, 1, 3, 4]], bij_TBNN[:, [0, 1, 3, 4]]), axis=1)\n",
    "# Use eddy_double_TBNN as the target variable, and eddy_double_LES as a reference\n",
    "Y = eddy_double_TBNN.ravel()\n",
    "Y_LES = eddy_double_LES.ravel()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define parameter grid for MLPRegressor hyperparameters\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization term\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Initialize an MLPRegressor\n",
    "mlp = MLPRegressor(solver='adam', random_state=42)\n",
    "\n",
    "# Perform GridSearchCV with 5-fold cross-validation to find best hyperparameters\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_scaled, Y)\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "print(\"Best hyperparameters from GridSearchCV:\", best_params)\n",
    "print(\"Best RMSE from GridSearchCV:\", best_rmse)\n",
    "\n",
    "# Initialize final MLPRegressor with the best hyperparameters\n",
    "final_mlp = MLPRegressor(solver='adam', random_state=42, **best_params)\n",
    "\n",
    "# Evaluate the model using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(final_mlp, X_scaled, Y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-np.mean(cv_scores))\n",
    "print(\"MLPRegressor Cross-validated RMSE:\", cv_rmse)\n",
    "\n",
    "# Get cross-validated predictions\n",
    "Y_pred_cv = cross_val_predict(final_mlp, X_scaled, Y, cv=kf)\n",
    "print(\"MLPRegressor Cross-validated R2:\", r2_score(Y, Y_pred_cv))\n",
    "\n",
    "# Train the final MLPRegressor on the full dataset\n",
    "final_mlp.fit(X_scaled, Y)\n",
    "Y_pred = final_mlp.predict(X_scaled)\n",
    "print(\"MLPRegressor Training RMSE:\", np.sqrt(mean_squared_error(Y, Y_pred)))\n",
    "print(\"MLPRegressor Training R2:\", r2_score(Y, Y_pred))\n",
    "\n",
    "# Plot predictions vs. actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_LES, label='Actual eddy_double_LES', color='green')\n",
    "plt.plot(Y, label='Actual eddy_double_TBNN', color='blue')\n",
    "plt.plot(Y_pred, label='MLP Prediction (Train)', color='red', linestyle='--')\n",
    "plt.plot(Y_pred_cv, label='MLP Prediction (CV)', color='orange', linestyle='-.')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('MLPRegressor Prediction vs. Actual')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Interpolate the results onto the spatial grid\n",
    "points = np.column_stack((x_point.ravel(), y_point.ravel()))\n",
    "eddy_double_LES_interp = griddata(points, eddy_double_LES.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "eddy_double_TBNN_interp = griddata(points, eddy_double_TBNN.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "Y_pred_interp = griddata(points, Y_pred.ravel(), (x, y), method='cubic').reshape(x.shape)\n",
    "\n",
    "# Set common color scale limits for the spatial plots\n",
    "vmin = -0.05\n",
    "vmax = 0.20\n",
    "\n",
    "# Plot the interpolated maps in a vertical stack (3 subplots)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 8))\n",
    "im0 = axs[0].pcolormesh(x, y, eddy_double_LES_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title('eddy double LES')\n",
    "axs[0].set_aspect('equal', adjustable='box')\n",
    "axs[0].set_xlim(np.min(x), np.max(x))\n",
    "axs[0].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im1 = axs[1].pcolormesh(x, y, eddy_double_TBNN_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_title('eddy double TBNN')\n",
    "axs[1].set_aspect('equal', adjustable='box')\n",
    "axs[1].set_xlim(np.min(x), np.max(x))\n",
    "axs[1].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "im2 = axs[2].pcolormesh(x, y, Y_pred_interp, shading='auto', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_title('MLPRegressor Y pred')\n",
    "axs[2].set_aspect('equal', adjustable='box')\n",
    "axs[2].set_xlim(np.min(x), np.max(x))\n",
    "axs[2].set_ylim(np.min(y), np.max(y))\n",
    "\n",
    "fig.subplots_adjust(right=0.85, hspace=0.1)\n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im2, cax=cbar_ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
